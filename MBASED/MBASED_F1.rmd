---
title: "F1 ASE Analysis with MBASED"
author: Lynn Ly
output: html_document
---

## This uses the MBASED package to analyze allele specific expression.  

  Single sample analysis: Find genes that display allelic imbalance ie. not expressed 0.5/0.5. Default threshold: 0.7 
  
  Two sample analysis: Find genes that display different ASE ratios between two samples with the SAME HAPLOTYPE. Doesn't matter what the actual ratios are, as long as they differ by over 0.2. **IMPORTANT:** Two sample analysis is one-tailed. In certain cases, a large but negative MAF difference, will still have a high p-value. This means results are NOT symmetrical, so pay attention to the order of the conditions  
  
**Inputs:** Pre-filtered VCF file, simplified gff file with just ranges and feature name  

**Outputs of this file:** Phased data with gene annotations and estimates of reference bias and dispersion  

End MBASED Outputs: major allele frequencies, frequency differences, list of genes displaying ASE  

```{r setup, include=FALSE}
library(MBASED)
library(tidyverse)
library(VGAM)
```

# AnnotateSNPs  

```{r AnnotateSNPs Function}
# Modified from Ruijuan's function in helpler.R
AnnotateSNPs <- function(SNPdata, gff.mRNA){
  # Combines SNP/SNV loci with gene names
  #
  # Args:
  #   SNP.data: SNP data containing positions to be matched with genomic features
  #   gff: A gff file containing only CHROM, START, END, GeneID
  #
  # Returns:
  #   SNP.data with a new column, GeneID
  
  colnames(gff.mRNA) <- c("CHROM", "start", "end", "name") 
  
  genes <- GRanges(seqnames = Rle(gff.mRNA$CHROM),
                   ranges = IRanges(start = gff.mRNA$start, end = gff.mRNA$end), 
                   names = gff.mRNA$name)
  
  SNPs <- GRanges(seqnames = Rle(SNPdata$CHROM), 
                 ranges = IRanges(start = SNPdata$POS, SNPdata$POS), 
                 CHROM = SNPdata$CHROM,
                 POS = SNPdata$POS)
  
  # Overlap SNP position with gene range 
  overlappedGenes <- mergeByOverlaps(SNPs, genes)
  overlappedGenes <- overlappedGenes[, c(2, 3, 5)]
  colnames(overlappedGenes) <- c("CHROM", "POS", "GeneID")
  
  annotatedSNPdata <- SNPdata %>% 
    left_join(as.data.frame(overlappedGenes), by=c("CHROM", "POS")) 
  
  return(annotatedSNPdata)  
}
```

Functions for setting up the ASESummarizedExperiment input to `runMBASED()`

```{r Single and Two Sample Function}
# Please change numSim to at least 1,000,000 for final analysis

SingleSample <- function(annotatedData, mySNVs, genotype, numSim = 0, refBias = 0.5){
  # create RangedSummarizedExperiment object as input for runMBASED
  # then runMBASED
  
  RO <- paste(genotype, "RO", sep = "_")
  AO <- paste(genotype, "AO", sep = "_")
  
  mySample <- SummarizedExperiment(
    assays = list(lociAllele1Counts = matrix(annotatedData[, RO], ncol = 1, dimnames = list(names(mySNVs), 'mySample')),
                lociAllele2Counts = matrix(annotatedData[, AO], ncol = 1,  dimnames = list(names(mySNVs), 'mySample')),
                lociAllele1CountsNoASEProbs=matrix(annotatedData$refBias, 
                                                   ncol=1, dimnames=list(names(mySNVs), 'mySample'))

                ),
    rowRanges=mySNVs)
  
  MBASEDOutput <- runMBASED(
    ASESummarizedExperiment = mySample,
    numSim = numSim,
    isPhased = TRUE) 

  return(MBASEDOutput)
}

TwoSample <- function(annotatedData, mySNVs, genotype1, genotype2, numSim = 0){
  RO1 <- paste(genotype1, "RO", sep = "_")
  AO1 <- paste(genotype1, "AO", sep = "_")
  RO2 <- paste(genotype2, "RO", sep = "_")
  AO2 <- paste(genotype2, "AO", sep = "_")
  RAB1 <- paste(genotype1, "refBias", sep = "_")
  RAB2 <- paste(genotype2, "refBias", sep = "_")
  
  mySample <- SummarizedExperiment(
    assays = list(lociAllele1Counts = matrix(c(annotatedData[, RO1], annotatedData[, RO2]), ncol = 2,
                                             dimnames = list(names(mySNVs), c(genotype1, genotype2))),
                                             
                  lociAllele2Counts = matrix(c(annotatedData[, AO1], annotatedData[, AO2]), ncol = 2,
                                            dimnames = list(names(mySNVs), c(genotype1, genotype2))),
    
                  lociAllele1CountsNoASEProbs = matrix(c(annotatedData[, RAB1], annotatedData[, RAB2]),
                                                   ncol=2, dimnames=list(names(mySNVs), c(genotype1, genotype2)))),
    rowRanges=mySNVs)
  
  MBASEDOutput <- runMBASED(
    ASESummarizedExperiment = mySample,
    isPhased = TRUE,
    numSim = numSim
    #BPPARAM = SerialParam() # Default: No paralellization
  )
  
  return(MBASEDOutput)
} 
```

### Filtering Functions  
`CoverageFilter()` requires at least 10 reads for a SNV, and that at least 10% of all reads support each allele. **We may want to return to reads discarded by this**, especially ones that were discarded from the second clause. These may include genes where one allele is completely silenced.  
`RangeFilter()` discards SNVs that are within 10bp of another called SNV, in order to ensure read independence.  
```{r Filtering Functions}

CoverageFilter <- function(vcf) {
  # Modified from Ruijuan's function in helpler.R
  # Require at least 10 reads and at least 10% of all reads support each allele
  
  totalReads <- vcf$F1_414_DP
  alleles <- vcf[, c(19, 23)]
  vcf.filtered <- vcf[which(apply(alleles / totalReads, 1, min) > .10), ]
  
  totalReads <- vcf.filtered$F1_415_DP
  alleles <- vcf.filtered[, c(20, 24)]
  vcf.filtered <- vcf.filtered[which(apply(alleles / totalReads, 1, min) > .10), ]
  
  return(vcf.filtered) 
} 

RangeFilter <- function(vcf) {
  # Discard SNVs that are within 10 bp of another called SNV. 
  # This is necessary because if one read spans both SNVs, then our counts are not independent. 
  # There may be a more elegant way to do this
  
  SNV.ranges <- GRanges(seqnames = Rle(vcf$CHROM), 
                    ranges = IRanges(start = vcf$POS - 5, end = vcf$POS + 5),
                    CHROM = vcf$CHROM,
                    POS = vcf$POS)
  
  overlappedGenes <- mergeByOverlaps(SNV.ranges, SNV.ranges)
  
  # Get only the 10bp overlaps that were not self-overlaps
  overlappedGenes <- overlappedGenes[which(overlappedGenes$POS != overlappedGenes$POS.1),]
  
  # Trim to just the relevant columns, CHROM and POS
  overlappedGenes <- as.data.frame(overlappedGenes)[, c(8, 9, 17, 18)]
  overlappedGenes <- mutate(overlappedGenes, SNV = paste(CHROM, POS), SNV_match = paste(CHROM.1, POS.1))
  
  # We don't want to get rid of all the SNVs though. We want to keep as many SNVs as possible that aren't overlapping. 
  i <- 1
  while(i <= nrow(overlappedGenes)) {
    if (overlappedGenes$SNV[i] %in% overlappedGenes$SNV_match) {
      overlappedGenes <- overlappedGenes[-i, ]
    } else {
    i <- i + 1
    }
  }

  rangeFilteredData <- anti_join(vcf, as.data.frame(overlappedGenes), by = c("CHROM", "POS"))
}
```

### Global Reference Bias and Dispersion

`CalcReferenceBias()` is based on this quote from the paper: "We assumed that fref,SNV (0.5) is constant across all SNVs within a sample (global reference bias), and we estimated this value as  
`Nref/Ntotal`  
which is the ratio of all reference reads to total reads in the sample, after excluding the loci with the top 5% of read counts (trimmed for robustness)"

`CalcDispersion()` finds the most likely rho (dispersion) for our data using **maximum likelihood estimation.**  
The purpose of this is to estimate the parameters we need to use when MBASED samples from a beta-binomial distribution.  
```{r Estimate Overdispersion and Reference Allele Bias}
# If our data presents any, we should include these metrics when creating mySNVs. 
# Use the additional functions in MBASED

# Reference Allele Bias is sample-specific and should be recalculated for each sample. 
CalcReferenceBias <- function(vcf, genotype) {
  RO <- paste(genotype, "RO", sep = "_")
  DP <- paste(genotype, "DP", sep = "_")
  
  cutoff <- 0.95 * nrow(vcf)
  orderedRO <- sort(vcf[, RO])
  orderedDP <- sort(vcf[, DP])
  
  Nref <- sum(head(orderedRO, cutoff))
  Ntotal <- sum(head(orderedDP, cutoff))
  
  globalReferenceBias <- Nref / Ntotal
  
  return(globalReferenceBias)
}

CalcDispersion <- function(vcf, genotype, refBias) {
  RO <- paste(genotype, "RO", sep = "_")
  DP <- paste(genotype, "DP", sep = "_")
  AO <- paste(genotype, "AO", sep = "_")
  
  # To eliminate potential artifacts that may affect the model fit, we require that the SNV be detected in at least 2 samples, with at least one sample presenting the reference as major and one presenting the alternate as major
  # I'm not sure if this should apply to our data. We already pooled our samples; should we depool?
  # However, without this step, the dispersion far exceeds the "normal" range.
  vcf <- vcf %>%
    mutate(F1_414_ROFreq = F1_414_RO / F1_414_DP > 0.5,
           F1_415_ROFreq = F1_415_RO / F1_415_DP > 0.5) %>%
    filter(F1_414_ROFreq != F1_415_ROFreq)
  
  # Log Likelihood Function to help us maximize rho (dispersion) using mle()
  ll <- function(rho) {
    x <- vcf[, RO]
    total <- vcf[, DP]
    mu <- refBias
    -sum(VGAM::dbetabinom(x, total, mu, rho, log = TRUE))
  }
  
  # Maximum likelihood function. Goal: Find ideal rho, given the data and our previously measured reference bias
  m <- mle(ll, start = list(rho = 0.000001), method = "L-BFGS-B", lower = 0.000001, upper = 0.10 )
  rho1 <- coef(m)
  print(paste0("The initial estimate for rho is ", rho1))
  
  # We must estimate the likelihood for the observed data under BetaBin(n = RO, mu = ref bias, rho = dispersion)
  # rho1 is the best p that maximizes the joint likelihood over all SNVs, but right now is not accurate due to outliers
  
  # Calculate the model based p-value at each SNV
  vcf$p <- pbetabinom(q = vcf[, RO], size = vcf[, DP], prob = refBias, rho = rho1)
  vcf$p2 <- pbetabinom(q = vcf[, AO], size = vcf[, DP], prob = 1 - refBias, rho = rho1)
  
  # Remove all SNVs with a BH-adjusted P < 0.05; these are outliers. There should not be too many, less than 1% of our total data.
  # NOTE: Since we are looking at so many SNVs, it seems that no multiple testing method will give P < 0.9
  # I am testing just removing the top (~0.1% of the data), since they are clearly in ASE and inflating the dispersion
  vcf$adjustedP <- p.adjust(vcf$p, method = "none")
  vcf$adjustedP2 <- p.adjust(vcf$p2, method = "none")
  
  print(paste0("Removing ", nrow(vcf[vcf$adjustedP < 0.01 | vcf$adjustedP2 < 0.01,]), " rows"))
  
  # Refit the model for our final estimate of rho
  
  ll <- function(rho) {
    x <- vcf[vcf$adjustedP > 0.01 & vcf$adjustedP2 > 0.01, RO]
    total <- vcf[vcf$adjustedP > 0.01 & vcf$adjustedP2 > 0.01, DP]
    mu <- refBias
    -sum(VGAM::dbetabinom(x, total, mu, rho, log = TRUE))
    }
  
  m <- mle(ll, start = list(rho = 0.000001), method = "L-BFGS-B", lower = 0.000001, upper = 0.10 )
  
  rhoFinal <- coef(m)
  print(paste0("The final rho is ", rhoFinal))
  return(rhoFinal)
  
  }

```


### Annotating and Filtering Data

```{r Annotating and Filtering Data}
gff.mRNA <- read.table("~/../ruijuanli/Reference/B.napus/gff.mRNA")

# Data to use (basically, VCF data pre-filtered for quality)
load("~/../mizukikadowaki/project/output/F1.young.GQ.filtered.Rdata")

annotatedData <- AnnotateSNPs(SNPdata = F1.young.GQ.filtered, gff.mRNA = gff.mRNA)
  
# Remove SNVs with no associated genes
annotatedData <- filter(annotatedData, !is.na(GeneID))
dim(annotatedData)

# The following filters are applied to avoid spurious ASE calls.

# Require at least 5 reads and at least 10% of all reads support each allele
annotatedData <- CoverageFilter(annotatedData)
dim(annotatedData)

# Discard all SNVs within 10 bp of another called variant (if one read spans both SNVs, some independence assumptions are violated)
annotatedData <- RangeFilter(annotatedData)
dim(annotatedData)

# NOT AVAILABLE FOR B NAPUS. Discard all SNVs in highly repetitive genomic regions, which we defined as regions with sequence identity of > 95% to another genomic region based on selfChain Link track from UCSC genome browser.
```

### Calculating reference bias and dispersion, and then phasing the data 

```{r Phasing Data}
inputVCF <- annotatedData

# Calculate the reference bias for each sample separately. 
refBias414 <- CalcReferenceBias(inputVCF, "F1_414") # 0.5107107 unfiltered, 0.509284 filtered
refBias415 <- CalcReferenceBias(inputVCF, "F1_415") # 0.5152294 unfiltered, 0.513306 filtered

dispersion414 <- CalcDispersion(inputVCF, "F1_414", refBias414)
dispersion415 <- CalcDispersion(inputVCF, "F1_415", refBias415)

inputVCF$F1_414_disp <- dispersion414
inputVCF$F1_415_disp <- dispersion415

# Now that necessary parameters have been calculated, phase the data so that all REF is from Da_Ae
inputVCF.Ae <- inputVCF[inputVCF$Ae_GT == 1, ]
inputVCF.Ae$F1_414_refBias <- refBias414
inputVCF.Ae$F1_415_refBias <- refBias415
inputVCF.Ol <- inputVCF[inputVCF$Ol_GT == 1, ]
inputVCF.Ol$F1_414_refBias <- 1 - refBias414
inputVCF.Ol$F1_415_refBias <- 1 - refBias415

# Switch the Ref and Alt alleles, and change the counts accordingly
colnames(inputVCF.Ol)[3:4] <- c("ALT", "REF")
colnames(inputVCF.Ol)[17:24] <- c("Ae_AO", "Ol_AO", "F1_414_AO", "F1_415_AO",
                                  "Ae_RO", "Ol_RO", "F1_414_RO", "F1_415_RO")

phasedData.unordered <- rbind(inputVCF.Ae, inputVCF.Ol)
phasedData <- phasedData.unordered %>% arrange(CHROM, POS)

newGene <- rep(NA, nrow(phasedData))
for(i in 38000:nrow(phasedData)) {
  if(phasedData[i, "GeneID"] != phasedData[i-1, "GeneID"]) {
    newGene[i] <- TRUE 
  } else {
    newGene[i] <- FALSE
  }
  if(i %% 100 == 0) {
    print(i)
  }
}

phasedData$newGene <- newGene

save(phasedData, file = "phasedData.Rdata")
```

The data is now prepared to be used in **Run_MBASED.R** and **Run_MBASED_Beta.R**
