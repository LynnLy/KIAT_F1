---
title: "Sleuth Differential Expression Analysis"
author: "Lynn Ly"
date: "February 16, 2018"
output: html_document
---

```{r setup, include=FALSE}
library(sleuth)
```

## Preliminaries

```{r}
sample_id <- dir(file.path("results"))

kal_dirs <- file.path("results", sample_id, "kallisto")
kal_dirs
```

The next step is to load an auxillary table that describes the experimental design and the relationship between the kallisto directories and the samples:

Also, Now the directories must be appended in a new column to the table describing the experiment.
This column must be labeled `path`, otherwise sleuth will report an error.
This is to ensure that samples can be associated with kallisto quantifications.

```{r}
metadata <- read.csv(file.path("F1_summary.csv"), header = TRUE, stringsAsFactors=FALSE)
metadata <- metadata[1:6, ]# young tissue only
metadata <- dplyr::mutate(metadata, path = kal_dirs)
metadata <- dplyr::select(metadata[1:6, ], sample = Sample.ID, cultivar, path, rep)
```

Next, the "sleuth object" can be constructed. This object will store not only the information about the experiment, but also details of the model to be used for differential testing, and the results.
It is prepared and used with four commands that (1) load the kallisto processed data into the object (2) estimate parameters for the __sleuth__ response error measurement (full) model (3) estimate parameters for the __sleuth__ reduced model, and (4) perform differential analysis (testing) using the likelihood ratio test. On a laptop the four steps should take about a few minutes altogether.

The sleuth object must first be initialized with

```{r cache=TRUE}
so <- sleuth_prep(metadata, extra_bootstrap_summary = TRUE)
```

Then the full model is fit with

```{r cache=TRUE}
so <- sleuth_fit(so, ~cultivar, 'full')
```

What this has accomplished is to "smooth" the raw kallisto abundance estimates for each sample using a linear model with a parameter that represents the experimental condition (in this case scramble vs. HOXA1KD).
To test for transcripts that are differential expressed between the conditions, sleuth performs a second fit to a "reduced" model that presumes abundances are equal in the two conditions.
To identify differential expressed transcripts sleuth will then identify transcripts with a significantly better fit with the "full" model.

The "reduced" model is fit with

```{r cache=TRUE}
so <- sleuth_fit(so, ~1, 'reduced')
```

and the test is performed with
```{r}
so <- sleuth_fit(so, ~rep, 'reducedRep')
so <- sleuth_fit(so, ~rep + cultivar, 'fullRep')
so <- sleuth_lrt(so, 'reducedRep', 'fullRep')
``` 


```{r}
so <- sleuth_lrt(so, 'reduced', 'full')


save(so, file = "SleuthOutput.Rdata")
save(metadata, file = "metadata.Rdata")
#load("SleuthOutput.Rdata")
#load("metadata.Rdata")
```

In general, sleuth can utilize the likelihood ratio test with any pair of models that are nested, and other walkthroughs illustrate the power of such a framework for accounting for batch effects and more complex experimental designs.

The models that have been fit can always be examined with the `models()` function.

```{r}
models(so)
```

The results of the test can be examined with
```{r}
sleuth_table <- sleuth_results(so, 'reduced:full', 'lrt', show_all = FALSE)
sleuth_significant <- dplyr::filter(sleuth_table, qval <= 0.05)
head(sleuth_significant, 20)
dim(sleuth_significant) # Genes that are significantly differentially expressed
```

The table shown above displays the top 20 significant genes with a (Benjamini-Hochberg multiple testing corrected) q-value <= 0.05.

```{r}
plot_bootstrap(so, "BnaC09g40660D", units = "est_counts", color_by = "cultivar")
```


The easiest way to view and interact with the results is to generate the sleuth live site that allows for exploratory data analysis:

```{r eval=FALSE}
sleuth_live(so)
```

Among the tables and visualizations that can be explored with sleuth live are a number of plots that provide an overview of the experiment. For example, a PCA plot provides a visualization of the samples:
```{r}
plot_pca(so, color_by = 'cultivar')
```

Various quality control metrics can also be examined. The count distributions for each sample (grouped by condition) can be displayed using the `plot_group_density` command:

```{r}
plot_group_density(so, use_filtered = TRUE, units = "est_counts",
  trans = "log", grouping = setdiff(colnames(so$sample_to_covariates),
  "sample"), offset = 1)
```


